{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Transformation Pipeline\n",
    "\n",
    "In this notebook we're going to explore the concepts and processes for defining a simple set of operators that will perform image pre-processing before they are feed into our model(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: kfp in /opt/conda/lib/python3.6/site-packages (0.1.27)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil in /opt/conda/lib/python3.6/site-packages (from kfp) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML in /opt/conda/lib/python3.6/site-packages (from kfp) (5.1)\n",
      "Requirement already satisfied, skipping upgrade: kubernetes<=9.0.0,>=8.0.0 in /opt/conda/lib/python3.6/site-packages (from kfp) (9.0.0)\n",
      "Requirement already satisfied, skipping upgrade: PyJWT>=1.6.4 in /opt/conda/lib/python3.6/site-packages (from kfp) (1.7.1)\n",
      "Requirement already satisfied, skipping upgrade: certifi in /opt/conda/lib/python3.6/site-packages (from kfp) (2019.3.9)\n",
      "Requirement already satisfied, skipping upgrade: kfp-server-api<=0.1.25,>=0.1.18 in /opt/conda/lib/python3.6/site-packages (from kfp) (0.1.18.3)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.15 in /opt/conda/lib/python3.6/site-packages (from kfp) (1.24.2)\n",
      "Requirement already satisfied, skipping upgrade: requests-toolbelt>=0.8.0 in /opt/conda/lib/python3.6/site-packages (from kfp) (0.9.1)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-storage>=1.13.0 in /opt/conda/lib/python3.6/site-packages (from kfp) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle in /opt/conda/lib/python3.6/site-packages (from kfp) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: cryptography>=2.4.2 in /opt/conda/lib/python3.6/site-packages (from kfp) (2.6.1)\n",
      "Requirement already satisfied, skipping upgrade: argo-models==2.2.1a in /opt/conda/lib/python3.6/site-packages (from kfp) (2.2.1a0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10 in /opt/conda/lib/python3.6/site-packages (from kfp) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth>=1.6.1 in /opt/conda/lib/python3.6/site-packages (from kfp) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: tabulate==0.8.3 in /opt/conda/lib/python3.6/site-packages (from kfp) (0.8.3)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema>=3.0.1 in /opt/conda/lib/python3.6/site-packages (from kfp) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: click==7.0 in /opt/conda/lib/python3.6/site-packages (from kfp) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=21.0.0 in /opt/conda/lib/python3.6/site-packages (from kubernetes<=9.0.0,>=8.0.0->kfp) (41.0.1)\n",
      "Requirement already satisfied, skipping upgrade: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.6/site-packages (from kubernetes<=9.0.0,>=8.0.0->kfp) (0.56.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/lib/python3.6/site-packages (from kubernetes<=9.0.0,>=8.0.0->kfp) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib in /opt/conda/lib/python3.6/site-packages (from kubernetes<=9.0.0,>=8.0.0->kfp) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: google-resumable-media>=0.3.1 in /opt/conda/lib/python3.6/site-packages (from google-cloud-storage>=1.13.0->kfp) (0.3.2)\n",
      "Requirement already satisfied, skipping upgrade: google-api-core<2.0.0dev,>=1.6.0 in /opt/conda/lib/python3.6/site-packages (from google-cloud-storage>=1.13.0->kfp) (1.9.0)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-core<0.30dev,>=0.29.0 in /opt/conda/lib/python3.6/site-packages (from google-cloud-storage>=1.13.0->kfp) (0.29.1)\n",
      "Requirement already satisfied, skipping upgrade: cffi!=1.11.3,>=1.8 in /opt/conda/lib/python3.6/site-packages (from cryptography>=2.4.2->kfp) (1.12.3)\n",
      "Requirement already satisfied, skipping upgrade: asn1crypto>=0.21.0 in /opt/conda/lib/python3.6/site-packages (from cryptography>=2.4.2->kfp) (0.24.0)\n",
      "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth>=1.6.1->kfp) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.6/site-packages (from google-auth>=1.6.1->kfp) (0.2.5)\n",
      "Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from google-auth>=1.6.1->kfp) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema>=3.0.1->kfp) (0.15.1)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema>=3.0.1->kfp) (19.1.0)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->kubernetes<=9.0.0,>=8.0.0->kfp) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->kubernetes<=9.0.0,>=8.0.0->kfp) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from requests-oauthlib->kubernetes<=9.0.0,>=8.0.0->kfp) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.4.0 in /opt/conda/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage>=1.13.0->kfp) (3.7.1)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos!=1.5.4,<2.0dev,>=1.5.3 in /opt/conda/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage>=1.13.0->kfp) (1.5.9)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /opt/conda/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage>=1.13.0->kfp) (2019.1)\n",
      "Requirement already satisfied, skipping upgrade: pycparser in /opt/conda/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.4.2->kfp) (2.19)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /opt/conda/lib/python3.6/site-packages (from rsa>=3.1.4->google-auth>=1.6.1->kfp) (0.4.5)\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install kfp --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.components as comp\n",
    "import kfp.dsl as dsl\n",
    "from kfp import compiler\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.enable_eager_execution()\n",
    "import IPython.display as display\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_datasets_op = comp.func_to_container_op(read_records)\n",
    "create_tf_datasets_op = comp.func_to_container_op(create_tf_datasets)\n",
    "parse_images_op = comp.func_to_container_op(parse_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.python_component(\n",
    "    name=\"img_preprocessing_pipline\",\n",
    "    description=\"Image preprocessing pipeline for learning to steer\")\n",
    "\n",
    "def test_nfs(server_ip: str) -> str:\n",
    "    \n",
    "\n",
    "def preprocess(dataset_path: str, num_examples: int, output_dir: str,\n",
    "               batch_size: int) -> str:\n",
    "    \"\"\"\n",
    "    Image preprocessing pipeline\n",
    "    \"\"\"\n",
    "    import json\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.python.lib.io import file_io\n",
    "    from sklearn.utils import shuffle\n",
    "    \n",
    "    # TODO Move configuration related vars out to config file\n",
    "    record_dir = 'tfrecords/2148-09-02-2019/tfrecords'\n",
    "    \n",
    "    # Create a dictionary describing the features.\n",
    "    # TODO : define in config file? might be too kludgey from a UX perspective?\n",
    "    image_feature_description = {\n",
    "        'timestamp': tf.FixedLenFeature([], tf.float32),\n",
    "        'image': tf.FixedLenFeature([], tf.string),\n",
    "        'steering_theta': tf.FixedLenFeature([], tf.float32),\n",
    "        'accelerator': tf.FixedLenFeature([], tf.float32),\n",
    "        'height': tf.FixedLenFeature([], tf.int64),\n",
    "        'width': tf.FixedLenFeature([], tf.int64),\n",
    "        'capture_height': tf.FixedLenFeature([], tf.int64),\n",
    "        'capture_width': tf.FixedLenFeature([], tf.int64),\n",
    "        'capture_fps': tf.FixedLenFeature([], tf.int64),\n",
    "        'num_channels': tf.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    \n",
    "    def read_records(directory: str) -> list:\n",
    "        \"\"\"\n",
    "        Read all files in a directory and return a list containing all \n",
    "        of the filenames.\n",
    "        \"\"\"\n",
    "        filenames = [f for f in listdir(directory) if isfile(join(directory, f))]\n",
    "        return filenames\n",
    "\n",
    "    def create_tf_datasets(filenames: list) -> list:\n",
    "        raw_image_datasets = []\n",
    "\n",
    "        for record in read_records(record_dir):\n",
    "            raw_image_datasets.append(tf.data.TFRecordDataset(f'{record_dir}/{record}'))\n",
    "\n",
    "        return raw_image_datasets\n",
    "\n",
    "    # raw_image_datasets = []\n",
    "\n",
    "    # for record in tfrecords:\n",
    "    #     raw_image_datasets.append(tf.data.TFRecordDataset(f'tfrecords/tfrecords/{record}'))\n",
    "\n",
    "    def parse_image_function(example_proto):\n",
    "      # Parse the input tf.Example proto using the dictionary above.\n",
    "        return tf.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "    def parse_datasets(datasets: list) -> list:\n",
    "        parsed_datasets = []\n",
    "\n",
    "        for raw_image_dataset in raw_image_datasets:\n",
    "            parsed_datasets.append(r.map(_parsed_image_function()))\n",
    "\n",
    "        return parsed_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_pipeline = preprocess\n",
    "pipeline_filename = preprocess_pipeline.__name__ = \".image.preprocess.tar.gz\"\n",
    "import kfp.compiler as compiler\n",
    "compiler.Compiler().compile(preprocess_pipeline, pipeline_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"/pipeline/#/experiments/details/7172b269-7e65-4fc6-8e92-f4d8518c12e1\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/93e24740-cf40-11e9-babe-ecf4bbea6fc4\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "EXPERIMENT_NAME = \"LEARN_TO_STEER\"\n",
    "import kfp\n",
    "client = kfp.Client()\n",
    "experiment = client.create_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "run_name = preprocess_pipeline.__name__ + ' run'\n",
    "run_result = client.run_pipeline(experiment.id, run_name, pipeline_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Transformation Pipeline.ipynb    project.mp4\r\n",
      "Lightweight components overview.ipynb  segment-0.avi\r\n",
      "mlpipeline-metrics.json\t\t       segment-1.avi\r\n",
      "mlpipeline-ui-metadata.json\t       segment-2.avi\r\n",
      "MNIST_data\t\t\t       segment-3.avi\r\n",
      "projec-1.avi\t\t\t       tfrecords\r\n",
      "projec-1.mp4\t\t\t       tfrrecords_deserialize.ipynb\r\n",
      "projec-2.avi\t\t\t       Untitled1.ipynb\r\n",
      "projec-2.mp4\t\t\t       Untitled.ipynb\r\n",
      "projec-3.avi\t\t\t       videos\r\n",
      "project.avi\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
